"""
Module de transformation des donn√©es de co√ªts cloud
Nettoie, enrichit et agr√®ge les donn√©es pour l'analyse
"""

import pandas as pd
import numpy as np
from datetime import datetime
import os
import glob


class CostTransformer:
    """Classe pour transformer et enrichir les donn√©es de co√ªts"""
    
    def __init__(self, input_file=None):
        """
        Args:
            input_file: Chemin vers le fichier CSV √† transformer
                       Si None, prend le dernier fichier dans data/raw/
        """
        if input_file is None:
            # Trouver le dernier fichier
            csv_files = glob.glob('data/raw/*.csv')
            if not csv_files:
                raise FileNotFoundError("Aucun fichier de donn√©es trouv√© dans data/raw/")
            input_file = max(csv_files, key=os.path.getctime)
        
        print(f"üìÇ Chargement : {input_file}")
        self.df = pd.read_csv(input_file)
        self.df['Date'] = pd.to_datetime(self.df['Date'])
        
        print(f"‚úÖ {len(self.df):,} lignes charg√©es\n")
    
    def clean_data(self):
        """Nettoie les donn√©es (valeurs manquantes, doublons, etc.)"""
        
        print("üßπ NETTOYAGE DES DONN√âES")
        print("-" * 60)
        
        initial_rows = len(self.df)
        
        # 1. Supprimer les doublons
        duplicates = self.df.duplicated().sum()
        self.df = self.df.drop_duplicates()
        print(f"   ‚ôªÔ∏è  Doublons supprim√©s : {duplicates}")
        
        # 2. Supprimer les lignes avec co√ªts n√©gatifs
        negative_costs = (self.df['Cost'] < 0).sum()
        self.df = self.df[self.df['Cost'] >= 0]
        print(f"   ‚õî Co√ªts n√©gatifs supprim√©s : {negative_costs}")
        
        # 3. G√©rer les valeurs manquantes
        missing_values = self.df.isnull().sum().sum()
        self.df = self.df.fillna({
            'Service': 'Unknown',
            'Region': 'Unknown',
            'AccountName': 'Unknown'
        })
        print(f"   üîß Valeurs manquantes trait√©es : {missing_values}")
        
        # 4. Arrondir les co√ªts √† 2 d√©cimales
        self.df['Cost'] = self.df['Cost'].round(2)
        
        final_rows = len(self.df)
        print(f"   üìä Lignes conserv√©es : {final_rows:,} / {initial_rows:,}")
        print()
        
        return self
    
    def add_time_dimensions(self):
        """Ajoute des dimensions temporelles pour l'analyse"""
        
        print("üìÖ AJOUT DE DIMENSIONS TEMPORELLES")
        print("-" * 60)
        
        # Extraire les composantes de date
        self.df['Year'] = self.df['Date'].dt.year
        self.df['Month'] = self.df['Date'].dt.month
        self.df['MonthName'] = self.df['Date'].dt.strftime('%B')
        self.df['Week'] = self.df['Date'].dt.isocalendar().week
        self.df['DayOfWeek'] = self.df['Date'].dt.dayofweek
        self.df['DayName'] = self.df['Date'].dt.strftime('%A')
        self.df['IsWeekend'] = self.df['DayOfWeek'].isin([5, 6])
        
        # P√©riode Year-Month pour agr√©gations
        self.df['YearMonth'] = self.df['Date'].dt.to_period('M').astype(str)
        
        print(f"   ‚úÖ Colonnes ajout√©es : Year, Month, Week, DayOfWeek, etc.")
        print(f"   üìÜ P√©riode couverte : {self.df['Date'].min().date()} ‚Üí {self.df['Date'].max().date()}")
        print()
        
        return self
    
    def categorize_services(self):
        """Cat√©gorise les services AWS par type"""
        
        print("üè∑Ô∏è  CAT√âGORISATION DES SERVICES")
        print("-" * 60)
        
        # D√©finir les cat√©gories
        categories = {
            'Compute': ['EC2', 'Lambda', 'ECS', 'Fargate', 'Batch'],
            'Storage': ['S3', 'EBS', 'EFS', 'Glacier'],
            'Database': ['RDS', 'DynamoDB', 'ElastiCache', 'Redshift'],
            'Networking': ['VPC', 'CloudFront', 'Route53', 'Data Transfer', 'NAT Gateway'],
            'Analytics': ['Athena', 'EMR', 'Kinesis', 'QuickSight'],
            'Security': ['IAM', 'KMS', 'Secrets Manager', 'GuardDuty'],
            'Management': ['CloudWatch', 'Config', 'Systems Manager']
        }
        
        def get_category(service):
            """D√©termine la cat√©gorie d'un service"""
            for category, keywords in categories.items():
                if any(keyword.lower() in service.lower() for keyword in keywords):
                    return category
            return 'Other'
        
        self.df['ServiceCategory'] = self.df['Service'].apply(get_category)
        
        # Statistiques
        category_counts = self.df['ServiceCategory'].value_counts()
        print(f"   üì¶ Cat√©gories cr√©√©es : {len(category_counts)}")
        for cat, count in category_counts.items():
            print(f"      ‚Ä¢ {cat:15s} : {count:,} enregistrements")
        print()
        
        return self
    
    def calculate_aggregations(self):
        """Calcule diff√©rentes agr√©gations des co√ªts"""
        
        print("üî¢ CALCUL DES AGR√âGATIONS")
        print("-" * 60)
        
        # 1. Co√ªts journaliers totaux
        self.daily_costs = self.df.groupby('Date').agg({
            'Cost': 'sum'
        }).reset_index()
        self.daily_costs.columns = ['Date', 'TotalCost']
        print(f"   ‚úÖ Agr√©gation journali√®re : {len(self.daily_costs)} jours")
        
        # 2. Co√ªts par service et par jour
        self.daily_service_costs = self.df.groupby(['Date', 'Service']).agg({
            'Cost': 'sum'
        }).reset_index()
        print(f"   ‚úÖ Co√ªts par service/jour : {len(self.daily_service_costs)} lignes")
        
        # 3. Co√ªts mensuels par compte
        if 'AccountName' in self.df.columns:
            self.monthly_account_costs = self.df.groupby(['YearMonth', 'AccountName']).agg({
                'Cost': 'sum'
            }).reset_index()
            print(f"   ‚úÖ Co√ªts mensuels par compte : {len(self.monthly_account_costs)} lignes")
        
        # 4. Co√ªts par cat√©gorie de service
        self.category_costs = self.df.groupby(['Date', 'ServiceCategory']).agg({
            'Cost': 'sum'
        }).reset_index()
        print(f"   ‚úÖ Co√ªts par cat√©gorie : {len(self.category_costs)} lignes")
        
        # 5. Co√ªts par r√©gion
        if 'Region' in self.df.columns:
            self.region_costs = self.df.groupby(['Date', 'Region']).agg({
                'Cost': 'sum'
            }).reset_index()
            print(f"   ‚úÖ Co√ªts par r√©gion : {len(self.region_costs)} lignes")
        
        print()
        return self
    
    def calculate_kpis(self):
        """Calcule les KPIs m√©tier"""
        
        print("üìä CALCUL DES KPIs")
        print("-" * 60)
        
        # KPI 1 : Co√ªt total
        total_cost = self.df['Cost'].sum()
        print(f"   üí∞ Co√ªt total : ${total_cost:,.2f}")
        
        # KPI 2 : Co√ªt moyen journalier
        avg_daily_cost = self.daily_costs['TotalCost'].mean()
        print(f"   üìà Co√ªt moyen/jour : ${avg_daily_cost:,.2f}")
        
        # KPI 3 : Tendance (variation entre premier et dernier mois)
        monthly_totals = self.df.groupby('YearMonth')['Cost'].sum().sort_index()
        if len(monthly_totals) >= 2:
            first_month = monthly_totals.iloc[0]
            last_month = monthly_totals.iloc[-1]
            trend = ((last_month - first_month) / first_month) * 100
            print(f"   üìâ Tendance : {trend:+.1f}% (vs premier mois)")
        
        # KPI 4 : Top 3 services les plus co√ªteux
        top_services = self.df.groupby('Service')['Cost'].sum().sort_values(ascending=False).head(3)
        print(f"   üèÜ Top 3 services :")
        for i, (service, cost) in enumerate(top_services.items(), 1):
            pct = (cost / total_cost) * 100
            print(f"      {i}. {service:25s} : ${cost:10,.2f} ({pct:.1f}%)")
        
        # KPI 5 : D√©tection d'anomalies (jours avec co√ªts > 2x la moyenne)
        mean_cost = self.daily_costs['TotalCost'].mean()
        std_cost = self.daily_costs['TotalCost'].std()
        threshold = mean_cost + (2 * std_cost)
        
        self.daily_costs['IsAnomaly'] = self.daily_costs['TotalCost'] > threshold
        anomalies = self.daily_costs[self.daily_costs['IsAnomaly']]
        
        print(f"   ‚ö†Ô∏è  Anomalies d√©tect√©es : {len(anomalies)} jours")
        if len(anomalies) > 0:
            print(f"      (co√ªts > ${threshold:,.2f})")
        
        # KPI 6 : R√©partition weekend vs semaine
        weekend_costs = self.df[self.df['IsWeekend'] == True]['Cost'].sum()
        weekday_costs = self.df[self.df['IsWeekend'] == False]['Cost'].sum()
        print(f"   üìÖ R√©partition :")
        print(f"      Semaine : ${weekday_costs:,.2f} ({weekday_costs/total_cost*100:.1f}%)")
        print(f"      Weekend : ${weekend_costs:,.2f} ({weekend_costs/total_cost*100:.1f}%)")
        
        # Stocker les KPIs dans un dictionnaire
        self.kpis = {
            'total_cost': total_cost,
            'avg_daily_cost': avg_daily_cost,
            'trend_pct': trend if len(monthly_totals) >= 2 else 0,
            'anomaly_count': len(anomalies),
            'weekend_pct': (weekend_costs / total_cost) * 100
        }
        
        print()
        return self
    
    def create_summary_report(self):
        """Cr√©e un rapport r√©capitulatif d√©taill√©"""
        
        print("üìã CR√âATION DU RAPPORT R√âCAPITULATIF")
        print("-" * 60)
        
        # Top 10 services
        top10_services = self.df.groupby('Service').agg({
            'Cost': 'sum'
        }).sort_values('Cost', ascending=False).head(10)
        top10_services['Percentage'] = (top10_services['Cost'] / self.df['Cost'].sum()) * 100
        top10_services = top10_services.round(2)
        
        # √âvolution mensuelle
        monthly_evolution = self.df.groupby('YearMonth').agg({
            'Cost': 'sum'
        }).reset_index()
        monthly_evolution.columns = ['Month', 'TotalCost']
        monthly_evolution['TotalCost'] = monthly_evolution['TotalCost'].round(2)
        
        # Par compte
        if 'AccountName' in self.df.columns:
            account_summary = self.df.groupby('AccountName').agg({
                'Cost': 'sum'
            }).sort_values('Cost', ascending=False)
            account_summary['Percentage'] = (account_summary['Cost'] / self.df['Cost'].sum()) * 100
            account_summary = account_summary.round(2)
        else:
            account_summary = None
        
        # Par cat√©gorie
        category_summary = self.df.groupby('ServiceCategory').agg({
            'Cost': 'sum'
        }).sort_values('Cost', ascending=False)
        category_summary['Percentage'] = (category_summary['Cost'] / self.df['Cost'].sum()) * 100
        category_summary = category_summary.round(2)
        
        self.summary = {
            'top10_services': top10_services,
            'monthly_evolution': monthly_evolution,
            'account_summary': account_summary,
            'category_summary': category_summary
        }
        
        print(f"   ‚úÖ Rapport cr√©√© avec {len(self.summary)} sections")
        print()
        
        return self
    
    def save_transformed_data(self):
        """Sauvegarde toutes les donn√©es transform√©es"""
        
        print("üíæ SAUVEGARDE DES DONN√âES TRANSFORM√âES")
        print("-" * 60)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # 1. Donn√©es principales enrichies
        main_file = f'data/processed/costs_enriched_{timestamp}.csv'
        self.df.to_csv(main_file, index=False)
        print(f"   ‚úÖ Donn√©es enrichies : {main_file}")
        
        # 2. Co√ªts journaliers
        daily_file = f'data/processed/daily_costs_{timestamp}.csv'
        self.daily_costs.to_csv(daily_file, index=False)
        print(f"   ‚úÖ Co√ªts journaliers : {daily_file}")
        
        # 3. Top 10 services
        top10_file = f'data/processed/top10_services_{timestamp}.csv'
        self.summary['top10_services'].to_csv(top10_file)
        print(f"   ‚úÖ Top 10 services : {top10_file}")
        
        # 4. √âvolution mensuelle
        monthly_file = f'data/processed/monthly_evolution_{timestamp}.csv'
        self.summary['monthly_evolution'].to_csv(monthly_file, index=False)
        print(f"   ‚úÖ √âvolution mensuelle : {monthly_file}")
        
        # 5. R√©sum√© par cat√©gorie
        category_file = f'data/processed/category_summary_{timestamp}.csv'
        self.summary['category_summary'].to_csv(category_file)
        print(f"   ‚úÖ R√©sum√© par cat√©gorie : {category_file}")
        
        # 6. KPIs en JSON
        import json
        kpi_file = f'data/processed/kpis_{timestamp}.json'
        with open(kpi_file, 'w') as f:
            json.dump(self.kpis, f, indent=2)
        print(f"   ‚úÖ KPIs : {kpi_file}")
        
        print()
        return self


def main():
    """Pipeline de transformation complet"""
    
    print("="*60)
    print("üîÑ TRANSFORMATION DES DONN√âES DE CO√õTS CLOUD")
    print("="*60 + "\n")
    
    try:
        # Cr√©er le transformateur
        transformer = CostTransformer()
        
        # Ex√©cuter le pipeline de transformation
        transformer \
            .clean_data() \
            .add_time_dimensions() \
            .categorize_services() \
            .calculate_aggregations() \
            .calculate_kpis() \
            .create_summary_report() \
            .save_transformed_data()
        
        print("="*60)
        print("‚úÖ TRANSFORMATION TERMIN√âE AVEC SUCC√àS")
        print("="*60)
        print("\nüìÅ Fichiers disponibles dans data/processed/")
        print("üéØ Prochaine √©tape : Visualisation avec Streamlit\n")
        
    except Exception as e:
        print(f"\n‚ùå Erreur lors de la transformation : {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()