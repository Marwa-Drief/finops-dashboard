# ðŸ“Š **RÃ‰CAPITULATIF COMPLET DU PROJET FINOPS DASHBOARD MULTI-CLOUD**

---

## ðŸŽ¯ **Vue d'Ensemble**

**Nom** : FinOps Dashboard - Analyse des CoÃ»ts Cloud Multi-Compte AWS + Azure

**Objectif** : Pipeline ETL automatisÃ© pour analyser, optimiser et visualiser les coÃ»ts cloud multi-providers

**Valeur Business** : RÃ©duction des coÃ»ts cloud de 15-30% via identification des optimisations et anomalies

**Niveau** : Projet professionnel production-ready

---

## ðŸ—ï¸ **Architecture Technique ComplÃ¨te**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ARCHITECTURE GLOBALE                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AWS COST  â”‚         â”‚   AZURE     â”‚         â”‚   AIRFLOW   â”‚
â”‚  EXPLORER   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   BILLING   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  SCHEDULER  â”‚
â”‚     API     â”‚         â”‚     API     â”‚         â”‚   (Docker)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â”‚                        â”‚
       â”‚                       â”‚                        â”‚
       â–¼                       â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EXTRACTION MULTI-CLOUD (Python)                  â”‚
â”‚         extract_multicloud_costs.py (AWS + Azure)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   DATA/RAW/    â”‚
                 â”‚  CSV Brutes    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           TRANSFORMATION (Pandas + Enrichissement)            â”‚
â”‚              transform_costs.py (ETL Logic)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚DATA/PROCESSED/ â”‚
                 â”‚ CSV + KPIs JSONâ”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                               â”‚
          â–¼                               â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   AMAZON S3  â”‚              â”‚  STREAMLIT   â”‚
  â”‚   (Archive)  â”‚              â”‚  DASHBOARD   â”‚
  â”‚  Multi-Date  â”‚              â”‚ (localhost)  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

## ðŸ“ **Structure ComplÃ¨te du Projet**

```
finops-dashboard/
â”‚
â”œâ”€â”€ ðŸ“‚ venv/                                    # Environnement virtuel Python 3.11
â”‚
â”œâ”€â”€ ðŸ“‚ data/
â”‚   â”œâ”€â”€ raw/                                    # DonnÃ©es brutes extraites
â”‚   â”‚   â”œâ”€â”€ cloud_costs_YYYYMMDD_HHMMSS.csv   # AWS brut
â”‚   â”‚   â””â”€â”€ multicloud_costs_YYYYMMDD.csv     # AWS + Azure unifiÃ©
â”‚   â””â”€â”€ processed/                              # DonnÃ©es transformÃ©es
â”‚       â”œâ”€â”€ costs_enriched_*.csv               # DonnÃ©es enrichies complÃ¨tes
â”‚       â”œâ”€â”€ daily_costs_*.csv                  # AgrÃ©gation journaliÃ¨re
â”‚       â”œâ”€â”€ top10_services_*.csv               # Top services
â”‚       â”œâ”€â”€ monthly_evolution_*.csv            # Ã‰volution mensuelle
â”‚       â”œâ”€â”€ category_summary_*.csv             # Par catÃ©gorie
â”‚       â””â”€â”€ kpis_*.json                        # KPIs calculÃ©s
â”‚
â”œâ”€â”€ ðŸ“‚ scripts/                                 # Scripts Python ETL
â”‚   â”œâ”€â”€ data_simulator.py                      # GÃ©nÃ©rateur donnÃ©es test multi-cloud
â”‚   â”œâ”€â”€ extract_costs.py                       # Extraction AWS seul
â”‚   â”œâ”€â”€ extract_azure_costs.py                 # Extraction Azure seul
â”‚   â”œâ”€â”€ extract_multicloud_costs.py            # Extraction unifiÃ©e AWS+Azure
â”‚   â”œâ”€â”€ transform_costs.py                     # Transformation Pandas
â”‚   â”œâ”€â”€ s3_uploader.py                         # Upload vers S3
â”‚   â”œâ”€â”€ check_data.py                          # VÃ©rification donnÃ©es
â”‚   â””â”€â”€ check_s3.py                            # VÃ©rification S3
â”‚
â”œâ”€â”€ ðŸ“‚ airflow/                                 # Apache Airflow (Orchestration)
â”‚   â”œâ”€â”€ dags/                                   # DAGs (Workflows)
â”‚   â”‚   â”œâ”€â”€ finops_pipeline_dag.py             # DAG principal ETL
â”‚   â”‚   â””â”€â”€ s3_cleanup_dag.py                  # Nettoyage S3 (30j)
â”‚   â”œâ”€â”€ logs/                                   # Logs Airflow
â”‚   â”œâ”€â”€ plugins/                                # Plugins customs
â”‚   â”œâ”€â”€ config/                                 # Configuration
â”‚   â”œâ”€â”€ docker-compose.yaml                     # Orchestration Docker
â”‚   â”œâ”€â”€ Dockerfile                              # Image custom avec deps
â”‚   â”œâ”€â”€ requirements.txt                        # DÃ©pendances Airflow
â”‚   â””â”€â”€ .env                                    # Variables env Airflow
â”‚
â”œâ”€â”€ ðŸ“‚ logs/                                    # Logs du pipeline Python
â”‚   â”œâ”€â”€ pipeline.log                            # Logs exÃ©cution
â”‚   â”œâ”€â”€ execution_history.json                  # Historique runs
â”‚   â””â”€â”€ report_*.txt                            # Rapports gÃ©nÃ©rÃ©s
â”‚
â”œâ”€â”€ ðŸ“„ .env                                     # Credentials (racine)
â”œâ”€â”€ ðŸ“„ .gitignore                               # Fichiers Ã  ignorer Git
â”œâ”€â”€ ðŸ“„ dashboard.py                             # Dashboard Streamlit multi-cloud
â”œâ”€â”€ ðŸ“„ pipeline_orchestrator.py                 # Orchestrateur Python simple
â”œâ”€â”€ ðŸ“„ run_pipeline_now.py                      # ExÃ©cution manuelle pipeline
â”œâ”€â”€ ðŸ“„ view_pipeline_stats.py                   # Statistiques pipeline
â”œâ”€â”€ ðŸ“„ start_pipeline.bat                       # Lanceur Windows
â”œâ”€â”€ ðŸ“„ test_aws_connection.py                   # Test connexion AWS
â”œâ”€â”€ ðŸ“„ test_aws_connection_v2.py                # Test avancÃ© AWS
â””â”€â”€ ðŸ“„ README.md                                # Documentation complÃ¨te

```

---

## ðŸ”§ **Stack Technique ComplÃ¨te**

### **Backend & ETL**

| Technologie | Version | Usage |
| --- | --- | --- |
| **Python** | 3.11 | Langage principal |
| **boto3** | 1.34.34 | SDK AWS (Cost Explorer) |
| **azure-mgmt-costmanagement** | Latest | SDK Azure Billing |
| **azure-identity** | Latest | Authentification Azure |
| **pandas** | 2.1.4 | Manipulation de donnÃ©es |
| **Apache Airflow** | 2.7.3 | Orchestration pipelines |
| **Docker Compose** | Latest | Conteneurisation |

### **Storage & Data**

| Technologie | Usage |
| --- | --- |
| **CSV** | Stockage local donnÃ©es brutes/transformÃ©es |
| **JSON** | KPIs et mÃ©tadonnÃ©es |
| **Amazon S3** | Archive cloud long terme |
| **PostgreSQL** | Base de donnÃ©es Airflow |

### **Visualisation & Reporting**

| Technologie | Version | Usage |
| --- | --- | --- |
| **Streamlit** | 1.29.0 | Dashboard interactif web |
| **Plotly** | 5.18.0 | Graphiques interactifs |
| **Recharts** | - | Alternative visualisation |

### **DevOps & Infrastructure**

| Technologie | Usage |
| --- | --- |
| **Docker Desktop** | Conteneurisation Airflow |
| **WSL2** | Environnement Linux (optionnel) |
| **Git** | ContrÃ´le de version |
| **python-dotenv** | Gestion secrets |

### **Cloud Providers**

| Provider | Services UtilisÃ©s |
| --- | --- |
| **AWS** | Cost Explorer API, S3, IAM |
| **Azure** | Cost Management API, Service Principal, Entra ID |

---

## ðŸ”„ **Workflow du Pipeline ETL Complet**

### **Pipeline AutomatisÃ© (Airflow) - ExÃ©cution Quotidienne**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AIRFLOW SCHEDULER (Tous les jours Ã  8h00)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚               â”‚               â”‚
        â–¼               â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ã‰TAPE 1    â”‚ â”‚   Ã‰TAPE 2    â”‚ â”‚   Ã‰TAPE 3    â”‚ â”‚   Ã‰TAPE 4    â”‚
â”‚  EXTRACTION  â”‚â†’â”‚TRANSFORMATIONâ”‚â†’â”‚  UPLOAD S3   â”‚â†’â”‚NOTIFICATION  â”‚
â”‚  MULTI-CLOUD â”‚ â”‚   (Pandas)   â”‚ â”‚   (boto3)    â”‚ â”‚   (Logs)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

### **DÃ©tail des Ã‰tapes**

### **1ï¸âƒ£ EXTRACTION MULTI-CLOUD** (`extract_multicloud_costs.py`)

**Sources** :

- **AWS Cost Explorer API** : CoÃ»ts rÃ©els par service, rÃ©gion, compte
- **Azure Cost Management API** : CoÃ»ts rÃ©els par service, rÃ©gion, subscription

**Processus** :

```python
# AWS
aws_df = extract_aws_costs(start_date, end_date)
# Colonnes : Date, Cloud='AWS', Service, Region, Cost, Currency

# Azure
azure_df = extract_azure_costs(start_date, end_date)
# Colonnes : Date, Cloud='Azure', Service, Region, Cost, Currency

# Fusion
combined_df = pd.concat([aws_df, azure_df])

```

**Gestion des Erreurs** :

- Si AWS Ã©choue â†’ DonnÃ©es simulÃ©es AWS
- Si Azure Ã©choue â†’ Ligne placeholder Azure (coÃ»t $0)
- Si tout Ã©choue â†’ Alerte et arrÃªt pipeline

**Output** : `data/raw/multicloud_costs_YYYYMMDD_HHMMSS.csv`

---

### **2ï¸âƒ£ TRANSFORMATION** (`transform_costs.py`)

**A. Nettoyage**

```python
- Suppression doublons
- Suppression coÃ»ts nÃ©gatifs
- Gestion valeurs manquantes
- Normalisation formats (dates, montants)

```

**B. Enrichissement**

```python
# Dimensions temporelles
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['MonthName'] = df['Date'].dt.strftime('%B')
df['Week'] = df['Date'].dt.isocalendar().week
df['DayOfWeek'] = df['Date'].dt.dayofweek
df['DayName'] = df['Date'].dt.strftime('%A')
df['IsWeekend'] = df['DayOfWeek'].isin([5, 6])
df['YearMonth'] = df['Date'].dt.to_period('M')

# CatÃ©gorisation des services
categories = {
    'Compute': ['EC2', 'Lambda', 'Virtual Machines', 'Functions'],
    'Storage': ['S3', 'EBS', 'Storage Accounts'],
    'Database': ['RDS', 'DynamoDB', 'SQL Database', 'Cosmos DB'],
    'Networking': ['VPC', 'CloudFront', 'CDN', 'Virtual Network'],
    'Analytics': ['Athena', 'EMR', 'Kinesis'],
    'Security': ['IAM', 'KMS', 'GuardDuty'],
    'Management': ['CloudWatch', 'Config']
}
df['ServiceCategory'] = df['Service'].apply(categorize)

```

**C. AgrÃ©gations**

```python
# 1. CoÃ»ts journaliers totaux
daily_costs = df.groupby('Date')['Cost'].sum()

# 2. CoÃ»ts par service et jour
service_daily = df.groupby(['Date', 'Service'])['Cost'].sum()

# 3. CoÃ»ts mensuels par compte
monthly_account = df.groupby(['YearMonth', 'AccountName'])['Cost'].sum()

# 4. CoÃ»ts par catÃ©gorie
category_costs = df.groupby(['Date', 'ServiceCategory'])['Cost'].sum()

# 5. CoÃ»ts par cloud
cloud_costs = df.groupby(['Date', 'Cloud'])['Cost'].sum()

# 6. CoÃ»ts par rÃ©gion
region_costs = df.groupby(['Date', 'Region'])['Cost'].sum()

```

**D. Calcul des KPIs**

```python
kpis = {
    'total_cost': df['Cost'].sum(),
    'avg_daily_cost': daily_costs.mean(),
    'trend_pct': ((last_month - first_month) / first_month) * 100,
    'anomaly_count': len(anomalies),  # Jours > 2Ïƒ
    'weekend_pct': (weekend_costs / total_cost) * 100,
    'top_service': top_services.iloc[0],
    'top_cloud': df.groupby('Cloud')['Cost'].sum().idxmax()
}

```

**E. DÃ©tection d'Anomalies**

```python
# MÃ©thode statistique (z-score)
mean = daily_costs.mean()
std = daily_costs.std()
threshold = mean + (2 * std)
anomalies = daily_costs[daily_costs > threshold]

```

**Output** :

- `data/processed/costs_enriched_*.csv` (donnÃ©es complÃ¨tes)
- `data/processed/daily_costs_*.csv`
- `data/processed/top10_services_*.csv`
- `data/processed/monthly_evolution_*.csv`
- `data/processed/category_summary_*.csv`
- `data/processed/kpis_*.json`

---

### **3ï¸âƒ£ UPLOAD S3** (`s3_uploader.py`)

**Organisation S3** :

```
s3://finops-dashboard-data/
â”œâ”€â”€ processed/
â”‚   â””â”€â”€ daily/
â”‚       â””â”€â”€ 2025-10-26/
â”‚           â”œâ”€â”€ costs_enriched_20251026_083015.csv
â”‚           â””â”€â”€ daily_costs_20251026_083015.csv
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ 2025-10-26/
â”‚       â”œâ”€â”€ top10_services_20251026_083015.csv
â”‚       â””â”€â”€ monthly_evolution_20251026_083015.csv
â””â”€â”€ kpis/
    â””â”€â”€ 2025-10-26/
        â””â”€â”€ kpis_20251026_083015.json

```

**Code** :

```python
s3_client = boto3.client('s3')
s3_client.upload_file(
    local_path='data/processed/costs_enriched_*.csv',
    bucket='finops-dashboard-data',
    key=f'processed/daily/{today}/costs_enriched_{timestamp}.csv'
)

```

**RÃ©tention** : DAG de cleanup supprime fichiers > 30 jours

---

### **4ï¸âƒ£ NOTIFICATION** (`send_notification_task`)

**Rapport gÃ©nÃ©rÃ©** :

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           RAPPORT FINOPS - 26/10/2025 08:30           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                          â•‘
â•‘  ðŸ’° CoÃ»t Total        : $6,842.50                       â•‘
â•‘  ðŸ“Š CoÃ»t Moyen/Jour   : $75.19                          â•‘
â•‘  ðŸ“ˆ Tendance          : +12.3%                          â•‘
â•‘  âš ï¸  Anomalies         : 3 jours                         â•‘
â•‘                                                          â•‘
â•‘  â˜ï¸  AWS              : $4,505.25 (65.8%)               â•‘
â•‘  â˜ï¸  Azure            : $2,337.25 (34.2%)               â•‘
â•‘                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

```

**Logging** :

- `logs/pipeline.log` : Logs dÃ©taillÃ©s
- `logs/execution_history.json` : Historique des runs
- `logs/report_*.txt` : Rapports texte

---

## ðŸ“Š **Dashboard Streamlit - FonctionnalitÃ©s ComplÃ¨tes**

### **Interface Utilisateur**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ’° FinOps Dashboard - Multi-Cloud Cost Analysis        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  [ðŸ“Š 4 KPI CARDS]                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚ CoÃ»t     â”‚ CoÃ»t Moy â”‚ Tendance â”‚ Anomaliesâ”‚        â”‚
â”‚   â”‚ Total    â”‚ /Jour    â”‚ +12.3%   â”‚    3     â”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [â˜ï¸ COMPARAISON MULTI-CLOUD]                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   â”‚ Graphique Pie  â”‚ Tableau Stats  â”‚                  â”‚
â”‚   â”‚ AWS vs Azure   â”‚ Par Cloud      â”‚                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [ðŸ“ˆ 6 GRAPHIQUES INTERACTIFS]                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   â”‚ Ã‰volution      â”‚ RÃ©partition    â”‚                  â”‚
â”‚   â”‚ JournaliÃ¨re    â”‚ Services       â”‚                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   â”‚ Par CatÃ©gorie  â”‚ Par Compte     â”‚                  â”‚
â”‚   â”‚ (Barres)       â”‚ (Aires)        â”‚                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   â”‚ Hebdomadaire   â”‚ Tendance       â”‚                  â”‚
â”‚   â”‚ (Barres)       â”‚ Mensuelle      â”‚                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [ðŸ“‹ TOP 10 SERVICES]                                   â”‚
â”‚   Tableau dÃ©taillÃ© avec coÃ»ts, moyennes, parts         â”‚
â”‚                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [ðŸ’¾ EXPORT CSV]                                        â”‚
â”‚   Boutons tÃ©lÃ©chargement donnÃ©es filtrÃ©es              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[ðŸ” SIDEBAR FILTRES]
  ðŸ“… PÃ©riode (date picker)
  â˜ï¸  Cloud (AWS / Azure / Tous)
  ðŸ’¼ Compte (select)
  ðŸ“¦ CatÃ©gorie (select)

```

### **Graphiques DÃ©taillÃ©s**

**1. Ã‰volution JournaliÃ¨re** (`plot_daily_costs`)

- Type : Line chart
- Axe X : Date
- Axe Y : CoÃ»t USD
- Features : Zoom, hover dÃ©tails, markers

**2. RÃ©partition Services** (`plot_service_breakdown`)

- Type : Donut chart
- Top 10 services
- Affichage : % + montant

**3. CoÃ»ts par CatÃ©gorie** (`plot_category_costs`)

- Type : Horizontal bar chart
- CatÃ©gories : Compute, Storage, Database, etc.
- Couleurs : Gradient blues

**4. Comparaison Comptes** (`plot_account_comparison`)

- Type : Stacked area chart
- Multi-comptes AWS/Azure
- Ã‰volution temporelle

**5. Analyse Hebdomadaire** (`plot_weekday_analysis`)

- Type : Bar chart
- Lundi-Dimanche
- Couleurs : Semaine (bleu) vs Weekend (orange)

**6. Tendance Mensuelle** (`plot_monthly_trend`)

- Type : Line chart with markers
- Ã‰volution sur plusieurs mois
- Indicateur de croissance

**7. Comparaison Multi-Cloud** (`plot_cloud_comparison`)

- Type : Pie chart
- AWS vs Azure
- Couleurs : AWS (orange) / Azure (bleu)

### **FonctionnalitÃ©s AvancÃ©es**

**Filtres Dynamiques** :

```python
# Tous les filtres se cumulent
filtered_df = df[
    (df['Date'] >= start_date) &
    (df['Date'] <= end_date) &
    (df['Cloud'] == selected_cloud) &  # Si != 'Tous'
    (df['AccountName'] == selected_account) &  # Si != 'Tous'
    (df['ServiceCategory'] == selected_category)  # Si != 'Toutes'
]

```

**Export CSV** :

```python
# Export donnÃ©es filtrÃ©es
csv_data = filtered_df.to_csv(index=False)
st.download_button("TÃ©lÃ©charger CSV", csv_data)

# Export top 10 services
top10_csv = top_services.to_csv()
st.download_button("TÃ©lÃ©charger Top 10", top10_csv)

```

**Cache Streamlit** :

```python
@st.cache_data
def load_latest_data():
    # Cache les donnÃ©es pour Ã©viter rechargements
    return df, kpis, monthly_df

```

---

## â˜ï¸ **Configuration Cloud**

### **AWS - Services UtilisÃ©s**

**1. Cost Explorer**

- API : `ce:GetCostAndUsage`
- GranularitÃ© : Daily / Monthly
- Dimensions : Service, Region, LinkedAccount
- Gratuit : 12 mois Free Tier
- Activation : 24-48h de dÃ©lai

**2. Amazon S3**

- Bucket : `finops-dashboard-data`
- RÃ©gions : `us-east-1` (recommandÃ©)
- Stockage : ~250 KB/mois (donnÃ©es CSV)
- CoÃ»t : ~$0.01/mois

**3. IAM (Identity and Access Management)**

- Utilisateur : `finops_user`
- Policies :
    
    ```json
    {  "Version": "2012-10-17",  "Statement": [    {      "Effect": "Allow",      "Action": [        "ce:GetCostAndUsage",        "ce:GetCostForecast",        "ce:GetDimensionValues"      ],      "Resource": "*"    },    {      "Effect": "Allow",      "Action": [        "s3:PutObject",        "s3:GetObject",        "s3:ListBucket"      ],      "Resource": [        "arn:aws:s3:::finops-dashboard-data",        "arn:aws:s3:::finops-dashboard-data/*"      ]    }  ]}
    
    ```
    

**Credentials** :

```
AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
AWS_SECRET_ACCESS_KEY=wJalrXUtn...
AWS_REGION=us-east-1
S3_BUCKET_NAME=finops-dashboard-data

```

---

### **Azure - Services UtilisÃ©s**

**1. Cost Management API**

- Endpoint : `https://management.azure.com/subscriptions/{id}/providers/Microsoft.CostManagement/query`
- Scope : Subscription level
- GranularitÃ© : Daily
- Dimensions : ServiceName, ResourceLocation, SubscriptionName

**2. Service Principal (App Registration)**

- Nom : `finops-cost-reader`
- Type : Application
- Authentification : Client Secret
- Permissions : Cost Management Reader

**3. Azure Active Directory (Entra ID)**

- Tenant ID : Organisation Azure
- Client ID : Application ID
- Client Secret : GÃ©nÃ©rÃ© lors crÃ©ation

**Credentials** :

```
AZURE_TENANT_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
AZURE_CLIENT_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
AZURE_CLIENT_SECRET=votre_secret_azure
AZURE_SUBSCRIPTION_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx

```

**Configuration RBAC** :

```
Subscription â†’ Access Control (IAM)
â†’ Add role assignment
â†’ Role: Cost Management Reader
â†’ Assign to: finops-cost-reader

```

---

## ðŸ¤– **Orchestration Airflow - Configuration ComplÃ¨te**

### **Architecture Airflow**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AIRFLOW WEBSERVER                       â”‚
â”‚              http://localhost:8080                       â”‚
â”‚           (Interface Web + API REST)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AIRFLOW SCHEDULER                       â”‚
â”‚         (DÃ©clenchement des DAGs selon schedule)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   POSTGRESQL DB                          â”‚
â”‚          (MÃ©tadonnÃ©es, Ã©tat des DAGs, logs)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

### **DAG Principal : `finops_cost_analysis_pipeline`**

**Configuration** :

```python
default_args = {
    'owner': 'finops-team',
    'depends_on_past': False,
    'email': ['admin@company.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'finops_cost_analysis_pipeline',
    default_args=default_args,
    description='Pipeline ETL multi-cloud cost analysis',
    schedule_interval='0 8 * * *',  # Tous les jours Ã  8h
    start_date=days_ago(1),
    catchup=False,
    tags=['finops', 'aws', 'azure', 'costs'],
)

```

**TÃ¢ches** :

```python
# TÃ¢che 1 : Extraction
task_extract = PythonOperator(
    task_id='extract_costs_task',
    python_callable=extract_costs,
    dag=dag,
)

# TÃ¢che 2 : Transformation
task_transform = PythonOperator(
    task_id='transform_costs_task',
    python_callable=transform_costs,
    dag=dag,
)

# TÃ¢che 3 : Upload S3
task_upload = PythonOperator(
    task_id='upload_to_s3_task',
    python_callable=upload_to_s3,
    dag=dag,
)

# TÃ¢che 4 : Notification
task_notify = PythonOperator(
    task_id='send_notification_task',
    python_callable=send_notification,
    dag=dag,
)

# DÃ©pendances
task_extract >> task_transform >> task_upload >> task_notify

```

**Gestion des Erreurs** :

- Retry automatique : 2 fois, dÃ©lai 5 min
- Email en cas d'Ã©chec (si configurÃ©)
- Logs dÃ©taillÃ©s dans Airflow UI

---

### **DAG Secondaire : `finops_s3_cleanup`**

**Configuration** :

```python
schedule_interval='0 2 * * 0'  # Dimanche Ã  2h du matin

```

**Fonction** :

```python
def cleanup_old_files(**context):
    """Supprime fichiers S3 > 30 jours"""
    cutoff_date = datetime.now() - timedelta(days=30)
    s3 = boto3.client('s3')

    response = s3.list_objects_v2(Bucket=bucket)
    for obj in response['Contents']:
        if obj['LastModified'].replace(tzinfo=None) < cutoff_date:
            s3.delete_object(Bucket=bucket, Key=obj['Key'])

```

---

### **Docker Compose Airflow**

**Services** :

```yaml
services:
  postgres:         # Base de donnÃ©es
  airflow-webserver:  # Interface web (port 8080)
  airflow-scheduler:  # Planificateur
  airflow-init:     # Initialisation DB + user admin

```

**Volumes MontÃ©s** :

```yaml
volumes:
  - ./dags:/opt/airflow/dags              # DAGs
  - ./logs:/opt/airflow/logs              # Logs
  - ./plugins:/opt/airflow/plugins        # Plugins
  - ../data:/opt/airflow/data             # DonnÃ©es
  - ../scripts:/opt/airflow/scripts       # Scripts Python

```

---

## ðŸ“ˆ **DonnÃ©es CollectÃ©es & MÃ©triques**

### **Schema des DonnÃ©es Brutes**

```python
# Structure CSV brut (data/raw/)
{
    'Date': '2025-10-26',              # Date YYYY-MM-DD
    'Cloud': 'AWS',                    # AWS | Azure
    'Service': 'Amazon EC2',           # Nom du service
    'Region': 'us-east-1',             # RÃ©gion cloud
    'AccountName': 'Production',       # Nom du compte
    'AccountId': '123456789012',       # ID du compte
    'Cost': 15.50,                     # CoÃ»t en USD
    'Currency': 'USD'                  # Devise
}

```

### **Schema des DonnÃ©es Enrichies**

```python
# Structure CSV enrichi (data/processed/)
{
    # Colonnes originales
    'Date': datetime,
    'Cloud': str,
    'Service': str,
    'Region': str,
    'AccountName': str,
    'AccountId': str,
    'Cost': float,
    'Currency': str,

    # Dimensions temporelles ajoutÃ©es
    'Year': int,                       # 2025
    'Month': int,

```
